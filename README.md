# ðŸ§¹ Data Preprocessing & Cleaning â€“ Titanic Dataset (`train.csv`)

This project demonstrates a real-world data cleaning and preprocessing workflow using the **Titanic `train.csv` dataset** from Kaggle. The goal is to prepare the data for analysis and machine learning.

---

## ðŸš€ What This Project Covers

- Loading and inspecting the Titanic `train.csv` dataset
- Identifying and handling missing values
- Dropping irrelevant or redundant columns
- Filling missing values using median and mode
- Visualizing missing data before and after cleaning
- Creating a cleaned version of the dataset

---

## ðŸ“‚ Files Included

- `train.csv` â€“ Original dataset from Kaggle
- `data_cleaning.ipynb` â€“ Jupyter Notebook with preprocessing steps
- `missing_values_before.png` â€“ Heatmap before cleaning
- `missing_values_after.png` â€“ Heatmap after cleaning

---

## ðŸ›  Tools & Libraries

- Python
- Pandas
- Matplotlib
- Seaborn
- Jupyter Notebook

---

## ðŸ’¡ How to Run This Project

1. Clone this repository
2. Open `data_cleaning.ipynb` in Jupyter Notebook or VS Code
3. Run all cells to reproduce the cleaning process

---

## ðŸ“Ž Notes

- This project uses the **`train.csv`** file only (not `test.csv` or submission file).
- Data source: [Kaggle Titanic Dataset](https://www.kaggle.com/competitions/titanic/data)

---

## ðŸ“¬ Stay Connected

ðŸ”— Follow my data science journey at **[MgTechInsights](https://mgtechinsights.framer.website)**  
ðŸ”— Connect with me on [LinkedIn](https://www.linkedin.com/in/margaretmary-ajuruchi )
ðŸ“§ Contact me for freelance data projects or portfolio reviews

